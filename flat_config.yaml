
model:
  ET_Network_params:
    name : BaseEntityTypingNetwork
    network_params:
      encoder_params:
        name : DistilBERTEncoder
        bertlike_model_name: distilbert-base-uncased
        freeze_encoder : True
      type_encoder_params:
        name : OneHotTypeEncoder
        trainable: False
      input_projector_params:
        name : Classifier
        '0':
          in_features : encoder_dim
          out_features: 512
          use_dropout: True
        '1':
          in_features: 512
          out_features : type_number
          use_dropout: False
          activation: sigmoid


trainer:
  gpus: 1
  limit_train_batches: .1

data:
  dataset_paths:
    # train: datasets/toy_datasets/toy_bbn_train.json
    # dev: datasets/toy_datasets/toy_bbn_dev.json
    # test: datasets/toy_datasets/toy_bbn_test.json
    train: datasets/ren_et_al/bbn/train.json
    dev: datasets/ren_et_al/bbn/dev.json
    test: datasets/ren_et_al/bbn/test-12k.json
  tokenizer_params:
    name : BaseBERTTokenizedDataset
    bertlike_model_name: distilbert-base-uncased
    max_mention_words: 1
    max_right_words: 2
    max_left_words: 2
  dataloader_params:
    train:
      batch_size: 64
      shuffle: True
    dev:
      batch_size: 8
    test:
      batch_size: 8

logger:
  project : entity_typing_framework
  entity : noonebug
  offline : True