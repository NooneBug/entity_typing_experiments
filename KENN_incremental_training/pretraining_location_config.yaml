seed_everything : 1

model:
  loss_params:
    name : BCELossForET
  ET_Network_params:
    name : BaseEntityTypingNetwork
    network_params:
      encoder_params:
        name : DistilBERTEncoder
        bertlike_model_name: distilbert-base-uncased
        freeze_encoder : True
      type_encoder_params:
        name : OneHotTypeEncoder
        trainable: False
      input_projector_params:
        name : Classifier
        layers_parameters: 
          '0':
            in_features : encoder_dim
            out_features: 512
            use_dropout: True
            activation: relu
          '1':
            in_features: 512
            out_features : type_number
            use_dropout: False
            activation: sigmoid

trainer:
  deterministic: True
  gpus: 1
  limit_train_batches: .1
  max_epochs : 100
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        dirpath: trained_models/pretraining/
        monitor: val_loss
        filename: pretraining_location
        save_weights_only: True
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        patience: 5
        monitor: val_loss
        mode: min
        verbose: True

data:
  dataset_paths:
    train: datasets/datasets_for_incremental_training/figer/pretraining_location.json
    dev: datasets/datasets_for_incremental_training/figer/pretraining_location_dev.json
    test: datasets/datasets_for_incremental_training/figer/pretraining_location_test.json
  dataset_reader_params:
    name : BaseDataset
  tokenizer_params:
    name : BaseBERTTokenizedDataset
    bertlike_model_name: distilbert-base-uncased
    max_mention_words: 1
    max_right_words: 1
    max_left_words: 1
  dataset_params:
    name: ET_Dataset
  dataloader_params:
    name: torch.DataLoader
    train:
      batch_size: 64
      shuffle: True
    dev:
      batch_size: 64
    test:
      batch_size: 64

logger:
  project : entity_typing_framework_prove
  entity : noonebug
  name : pretraining_figer_location