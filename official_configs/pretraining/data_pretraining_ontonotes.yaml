dataset_paths:
  train: ../datasets/datasets_for_incremental_training/ontonotes/pretraining/train.json
  dev: ../datasets/datasets_for_incremental_training/ontonotes/pretraining/dev.json
  test: ../datasets/datasets_for_incremental_training/ontonotes/pretraining/test.json
tokenizer_params:
  name : BaseBERTTokenizedDataset
  bertlike_model_name: bert-large-cased
  max_mention_words: 7
  max_right_words: 9
  max_left_words: 9
  max_tokens: 80
rw_options:
  modality: CreateAndSave # in [Create, CreateAndSave, Load]
  dirpath: ../tokenized_datasets/ontonotes/pretraining
  light: True
  # types_list_path: TBD